{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OdysseusPolymetis/journees_cluster5b_7/blob/main/3_nlp_lat_gk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z74vm47glyC"
      },
      "source": [
        "#**Tok√©niser, lemmatiser, √©tiqueter en latin et en grec**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt0eU-qsLb10"
      },
      "source": [
        "## De quoi s'agit-il ?\n",
        "Ici on va faire des exp√©riences sur ces trois points, n√©cessaires pour le traitement statistique notamment, la **tok√©nisation**, la **lemmatisation** et l'**√©tiquetage syntaxique**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLIKh_80WtdM"
      },
      "source": [
        "## Quelques petits outils utiles pour les non-programmeurs\n",
        "Cette liste est bien s√ªr non exhaustive, mais d'exp√©rience je pense qu'elle peut servir comme pis aller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31i7LBEP1HF9"
      },
      "source": [
        "##**Quelques outils en ligne**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P_eXTzr1Uup"
      },
      "source": [
        "###**UDPipe**\n",
        "Vous le trouverez [ici](https://lindat.mff.cuni.cz/services/udpipe/).\n",
        "<br>Vous pouvez l'utiliser pour des textes courts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDSIHDth4kxu"
      },
      "source": [
        "###**Deucalion**\n",
        "Vous le trouverez [ici](https://dh.chartes.psl.eu/deucalion/).\n",
        "<br>Je ne sais pas si c'est toujours maintenu, mais le mod√®le est correct, et l'usage facile."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbFh1tm45B9B"
      },
      "source": [
        "###**VoyantTools**\n",
        "Vous le trouverez [ici](https://voyant-tools.org/).\n",
        "<br>C'est un outil uniquement pour la visualisation, mais on peut faire des choses int√©ressantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj7F-HDpcCkK"
      },
      "source": [
        "##**Tok√©nisation, lemmatisation et postagging avec `stanza`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQIzGqJzcUVk"
      },
      "source": [
        "On va commencer par tester **`stanza`**. Il y a de tr√®s nombreux modules qui existent (comme`spacy` et `pie-extended`), mais `stanza` est assez facile √† utiliser (je trouve), et propose de tr√®s nombreuses langues (et surtout de tr√®s nombreux mod√®les par langue (4 pour le latin par exemple))."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "id": "MHhsLVo_LxjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try on a simple string first, which is encapsulated in the `catilinaires` variable."
      ],
      "metadata": {
        "id": "Hn8AvFjyNcgH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR5RRUfQc5u4"
      },
      "outputs": [],
      "source": [
        "catilinaires=\"Quousque tandem abutere, Catilina, patientia nostra ? Quamdiu etiam furor iste tuus nos eludet ? Quem ad finem sese effrenata jactabit audacia ? Nihilne te nocturnum praesidium Palatii, nihil urbis vigiliae, nihil timor populi, nihil concursus bonorum omnium, nihil hic munitissimus habendi senatus locus, nihil horum ora vultusque moverunt ? Patere tua consilia non sentis ? Constrictam jam horum omnium scientia teneri conjurationem tuam non vides ? Quid proxima, quid superiore nocte egeris, ubi fueris, quos convocaveris, quid consilii ceperis, quem nostrum ignorare arbitraris ? O tempora ! O mores ! Senatus haec intellegit, consul videt. Hic tamen vivit.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r_DV1BTw4Cr"
      },
      "source": [
        "###**stanza**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pourquoi je parle de `stanza` ici ? Parce que c'est effectivement de l'IA, mais pas forc√©ment comme on l'entend d'habitude. C'est de l'apprentissage profond, mais les mod√®les ne sont pas des transformers. Ce sont des architectures plus l√©g√®res (des encodeurs Bi-LSTM), entra√Æn√©es sur des textes d√©j√† √©tiquet√©s. L'avantage, c'est que c'est moins co√ªteux sur le plan computationnel, et plus contr√¥lable. En revanche, c'est plus strict et donc moins enclin √† la g√©n√©ralisation ou au hors domaine."
      ],
      "metadata": {
        "id": "HijGzrHjrla2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPEkXPIxeUob"
      },
      "source": [
        "`stanza` dispose de nombreux mod√®les (voil√† une [liste](https://stanfordnlp.github.io/stanza/performance.html)), que vous pouvez utiliser en appelant le code langue, comme `grc` pour le grec ancien ou `la` pour le latin. Mais vous pouvez aussi √™tre plus pr√©cis sur le mod√®le que vous souhaitez en particulier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJXi9pljw2DR"
      },
      "outputs": [],
      "source": [
        "import stanza\n",
        "stanza.download('la', package=\"perseus\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKCT-NaPxpbp"
      },
      "source": [
        "On commence par construire une pipeline, pour dire ce que l'on voudra utiliser (on ne prend pas le `ner` par exemple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x5kKE7rxTgB"
      },
      "outputs": [],
      "source": [
        "nlp_stanza = stanza.Pipeline(lang='la', package=\"perseus\", processors='tokenize,pos,lemma, depparse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUd62DkjgcvW"
      },
      "source": [
        "Ici la variable `catilinaires_analyzed` est un objet `stanza`, o√π sont encapsul√©es toutes les infos g√©n√©r√©es par le moteur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMPY243ZyE8S"
      },
      "outputs": [],
      "source": [
        "catilinaires_analyzed=nlp_stanza(catilinaires)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(catilinaires_analyzed)"
      ],
      "metadata": {
        "id": "YxQImmS0okFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSS-MkX_gr7m"
      },
      "source": [
        "Voil√† quelques r√©sultats, avec du d√©coupage en phrases, et un extrait des √©tiquettes obtenues."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`stanza` divise le texte en phrases, puis chaque phrase en une liste de tokens, qui ont tous des attributs type `.lemma`, ou `.pos`."
      ],
      "metadata": {
        "id": "U-ntk1krN7ZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQPdO0otBqA8"
      },
      "outputs": [],
      "source": [
        "for sent in catilinaires_analyzed.sentences:\n",
        "  print(\"XXXXX \"+sent.text+\" XXXXX\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNXzUVFZzojD"
      },
      "outputs": [],
      "source": [
        "for sent in catilinaires_analyzed.sentences:\n",
        "  for token in sent.words:\n",
        "    print(token.text + ' - ' + token.lemma + ' - ' + token.pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essayons maintenant avec un beaucoup plus gros texte."
      ],
      "metadata": {
        "id": "etySMAjIWQZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici je vous propose par d√©faut le texte de l'Odyss√©e, mais vous pouvez tester avec n'importe quel autre `.txt`, veillez simplement √† ne pas avoir de caract√®res hors unicode, et un texte en format plain text."
      ],
      "metadata": {
        "id": "au9q53YfJiCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "stanza.download('grc')\n",
        "import string"
      ],
      "metadata": {
        "id": "f2bHYAFOYfpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prenons _L'Odyss√©e_."
      ],
      "metadata": {
        "id": "D-eWZAZJKWaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/OdysseusPolymetis/digital_classics_course/refs/heads/main/odyssee_integrale.txt"
      ],
      "metadata": {
        "id": "zgUE5AS2NVSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/OdysseusPolymetis/digital_classics_course/refs/heads/main/stopwords_gk.txt\n",
        "!wget https://raw.githubusercontent.com/OdysseusPolymetis/digital_classics_course/refs/heads/main/stopwords_lat.txt"
      ],
      "metadata": {
        "id": "-RIcnkawyFTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour vos propres projets, vous pouvez trouver des listes de mots outils [ici](https://github.com/stopwords-iso). Moi je vais utiliser une version custom par d√©faut, mais c'est le m√™me principe. Je vous propose donc deux listes custom, il vous suffit de changer le chemin d'acc√®s au fichier en fonction de votre choix de langue (il suffit de changer `gk` en `lat` dans la cellule suivante)."
      ],
      "metadata": {
        "id": "RXgbxITmuxBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = open(\"/content/stopwords_gk.txt\",'r',encoding=\"utf8\").read().split(\"\\n\")"
      ],
      "metadata": {
        "id": "oOoC07eWyDxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'avantage d'utiliser des listes de mots outils inscrits dans un fichier est que vous pouvez ajouter vos propres mots en cliquant ici sur la gauche sur l'ic√¥ne dossier (üìÅ).\n",
        "<br>Si vous cliquez accidentellement (apr√®s avoir cliqu√© sur l'ic√¥ne dossier) sur la seconde ic√¥ne dossier (celle avec \"..\"), ne vous inqui√©tez pas : le dossier originel est en fait le dossier \"üìÅ `content`\", que vous pouvez aussi ouvrir."
      ],
      "metadata": {
        "id": "_reCsRP5vmqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez donc mettre votre propre texte en appuyant une fois sur le dossier, et vous pouvez faire un \"drag and drop\" de votre fichier. √âvitez, m√™me comme r√®gle g√©n√©rale, les espaces et les accents dans les fichiers et dossiers."
      ],
      "metadata": {
        "id": "H5U8yZVvwVuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une fois que vous avez mis votre texte, plusieurs choses √† v√©rifier.\n",
        "\n",
        "*   D'abord, changer le chemin vers votre fichier dans la cellule ci-dessous.\n",
        "*   Ensuite, v√©rifier le code langue de votre moteur, dans cette cellule :\n",
        "\n",
        "```python\n",
        "nlp_stanza = stanza.Pipeline(lang='fr', etc.)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7f6EKfBFwlmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_of_text = \"/content/odyssee_integrale.txt\""
      ],
      "metadata": {
        "id": "zCCJtvF2ZP1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_text = open(filepath_of_text, encoding=\"utf-8\").read()"
      ],
      "metadata": {
        "id": "Jb1ll9BDZS6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_stanza = stanza.Pipeline(lang='grc', processors='tokenize,pos,lemma')"
      ],
      "metadata": {
        "id": "bAPzFT46YugW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction qui suit permet simplement de mieux g√©rer la m√©moire."
      ],
      "metadata": {
        "id": "ZGmbsLUeMxac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_process(text, nlp, batch_size=100):\n",
        "    paragraphs = text.split('\\n')\n",
        "    batches = [paragraphs[i:i + batch_size] for i in range(0, len(paragraphs), batch_size)]\n",
        "\n",
        "    words = []\n",
        "\n",
        "    for batch in batches:\n",
        "        batch_text = '\\n'.join(batch)\n",
        "        doc = nlp(batch_text)\n",
        "        for sentence in doc.sentences:\n",
        "            for word in sentence.words:\n",
        "                token={}\n",
        "                if word.lemma is not None:\n",
        "                    token[\"word\"]=word.text\n",
        "                    token[\"lemma\"]=word.lemma\n",
        "                    token[\"pos\"]=word.pos\n",
        "                    words.append(token)\n",
        "\n",
        "    return words"
      ],
      "metadata": {
        "id": "APdiFA5ezDzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est la cellule suivante qui va prendre du temps."
      ],
      "metadata": {
        "id": "MhbPDxpMzOww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "odyssey = batch_process(full_text, nlp_stanza)"
      ],
      "metadata": {
        "id": "xIBpz_4nYjkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(odyssey[15:25])"
      ],
      "metadata": {
        "id": "x0tlOmanZaAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans la cellule suivante, on va prendre tous les tokens issus de l'analyse, et on va les stocker dans trois listes, `forms`, `lemmas` and `no_stop`. Dans la liste `forms`, on garde simplement les mots tels quels (le texte lui-m√™me donc). Dans la liste `lemmas`, on met tous les lemmes du texte. Enfin, dans la liste `no_stop`, on met tous les lemmes sans mots outils et sans ponctuation."
      ],
      "metadata": {
        "id": "xZjdWz6LPIj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va ensuite pouvoir utiliser ces listes pour une exp√©rience toute simple (qui montre l'utilit√© d'un pr√©-traitement correct)."
      ],
      "metadata": {
        "id": "plqd3RCpP-P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forms = []\n",
        "lemmas = []\n",
        "no_stop = []\n",
        "\n",
        "for token in miserables_analyzed:\n",
        "    form = token[\"word\"]\n",
        "    lemma = token[\"lemma\"]\n",
        "\n",
        "    if lemma not in string.punctuation:\n",
        "        forms.append(form)\n",
        "        lemmas.append(lemma)\n",
        "\n",
        "    if lemma not in string.punctuation and lemma not in stopwords:\n",
        "        no_stop.append(lemma)"
      ],
      "metadata": {
        "id": "KQMQx7NTa_Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deux cellules de v√©rification par la suite, vous devez obtenir plus que 0."
      ],
      "metadata": {
        "id": "BsYWv9SQQKJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(lemmas)"
      ],
      "metadata": {
        "id": "nRAm6ZDsdHBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(no_stop)"
      ],
      "metadata": {
        "id": "qGTu3w4hdI4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici pas la peine de comprendre en d√©tail, gardez juste √† l'id√©e que la fonction qui suit cr√©e un nuage de mots, qui va varier en fonction de la liste qu'on va lui passer en param√®tre. Les mots les plus importants (fr√©quence relative) apparaissent en gros."
      ],
      "metadata": {
        "id": "UOtonteIQVfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def create_word_cloud(words_list, title):\n",
        "    text = ' '.join(words_list)\n",
        "\n",
        "    radius = 495\n",
        "\n",
        "    diameter = radius * 2\n",
        "    center = radius\n",
        "    x, y = np.ogrid[:diameter, :diameter]\n",
        "    mask = (x - center) ** 2 + (y - center) ** 2 > radius ** 2\n",
        "    mask = 255 * mask.astype(int)\n",
        "\n",
        "    mask_rgba = np.dstack((mask, mask, mask, 255 - mask))\n",
        "\n",
        "    wordcloud = WordCloud(repeat=False, width=diameter, height=diameter,\n",
        "                          background_color=None, mode=\"RGBA\", colormap='plasma',\n",
        "                          mask=mask_rgba).generate(text)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9qv1DH7LdMhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_word_cloud(forms, 'Word Cloud for Forms')"
      ],
      "metadata": {
        "id": "h-wt9rK1eJpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_word_cloud(lemmas, 'Word Cloud for Lemmas')"
      ],
      "metadata": {
        "id": "t5B5uCAEeL5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_word_cloud(no_stop, 'Word Cloud for Lemmas without stopwords')"
      ],
      "metadata": {
        "id": "pKzLFQ6hec7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "J'ai ajout√© une petite cellule qui vous permet de t√©l√©charger les diff√©rentes listes dans des fichiers (par exemple si vous voulez les mettre dans Voyant Tools ou autre)."
      ],
      "metadata": {
        "id": "Gn5l_hECR9vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/forms.txt\", \"w\", encoding=\"utf8\") as f, open(\"/content/lemmas.txt\", \"w\", encoding=\"utf8\") as f2, open(\"/content/pullito.txt\", \"w\", encoding=\"utf8\") as f3:\n",
        "    f.write(\"\\n\".join(forms))\n",
        "    f2.write(\"\\n\".join(lemmas))\n",
        "    f3.write(\"\\n\".join(no_stop))"
      ],
      "metadata": {
        "id": "fXuX7UI9Sgaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Avec les `transformers`**"
      ],
      "metadata": {
        "id": "pLmfaEuv0oMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plusieurs avantages aux transformers:\n",
        "\n",
        "\n",
        "*   ils sont meilleurs pour le hors domaine (parce qu'ils sont entra√Æn√©s sur plein de langues en m√™me temps, ici par exemple sur du xlm-roberta), et donc potentiellement plus solides,\n",
        "*   ils g√®rent donc mieux les mots qu'ils ne connaissent pas, ainsi que les formes rares,\n",
        "*   ils sont assez faciles √† impl√©menter, et surtout √† affiner (sur des donn√©es personnalis√©es)\n",
        "<br>Le probl√®me c'est qu'ils restent lourds et co√ªteux.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XgDknZoF3e-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "name = \"wietsedv/xlm-roberta-base-ft-udpos28-grc\"\n",
        "tok = AutoTokenizer.from_pretrained(name)\n",
        "mdl = AutoModelForTokenClassification.from_pretrained(name)\n",
        "pos = pipeline(\"token-classification\", model=mdl, tokenizer=tok, aggregation_strategy=\"simple\")\n",
        "print(pos(\"·ºÄŒΩ·Ω¥œÅ œÉŒøœÜœåœÇ ·ºêœÉœÑŒπ.\"))"
      ],
      "metadata": {
        "id": "7DCc3mKreizB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et voici une petite d√©monstration de pourquoi on appelle √ßa un transformer (enfin pas vraiment, mais c'est l'id√©e) : le traitement simultan√© en plusieurs langues"
      ],
      "metadata": {
        "id": "tCEFxDpQIg6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "name = \"jordigonzm/mdeberta-v3-base-multilingual-pos-tagger\"\n",
        "tok = AutoTokenizer.from_pretrained(name)\n",
        "mdl = AutoModelForTokenClassification.from_pretrained(name)\n",
        "pos = pipeline(\"token-classification\", model=mdl, tokenizer=tok, aggregation_strategy=\"simple\")\n",
        "print(pos(\"·ºÄŒΩ·Ω¥œÅ œÉŒøœÜœåœÇ ·ºêœÉœÑŒπ.\"))\n",
        "print(pos(\"Aujourd'hui, maman est morte. Ou peut-√™tre hier, je ne sais pas.\"))"
      ],
      "metadata": {
        "id": "kUo5C4DE2imy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcrwQUYuKcJy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1hxMNZZBdsT9AyRKnXcdOnis82XnHDehl",
      "authorship_tag": "ABX9TyNABw0ekQObLNQ2VlrDr7SA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}